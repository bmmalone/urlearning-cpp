<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="running-the-urlearning-programs">Running the URLearning programs</h1>
<p>More details explaining the various program options will be added soon. Please follow <a href="https://github.com/bmmalone/urlearning-cpp/issues/3">Issue #3</a> to see the latest updates about documentation.</p>
<h2 id="local-score-calculations">Local score calculations</h2>
<p>The <code>score</code> program calculates the candidate parent sets used as input to the solvers. It accepts a csv file as input and produces a “<a href="http://urlearning.org/PSS-Keywords.odf">parent set scores</a>” (pss) file as output. Both URLearning and <a href="https://www.cs.york.ac.uk/aig/sw/gobnilp/">GOBNILP</a> can use pss files as input.</p>
<p>The <code>score</code> program treats each column as a categorical discrete variable, and each unique string is treated as a separate categorical value. In particular, the program <em>does not</em> perform any sort of discretization, normalization, etc. Furthermore, it <em>does not</em> remove records with missing values. String like “?”, “NA”, etc., will simply be treated as other categories for the variables for which they appear. Thus, it is likely custom preprocessing scripts will be necessary before using the <code>score</code> program.</p>
<p>By default, candidate parent sets which cannot possibly be optimal are pruned at the end of the <code>score</code> program; this behavior can be disabled with the <code>--do-not-prune</code> flag (see below). For more details about this pruning, please see:</p>
<p>Teyssier, M. &amp; Koller, D. Ordering-Based Search: A Simple and Effective Algorithm for Learning Bayesian Networks Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence, 2005 (the penultimate paragraph in Section 3.2).</p>
<pre><code>score &lt;input&gt; &lt;output&gt; [-c/--constraints &lt;constraints&gt;] [-d/--delimiter &lt;delimiter&gt;] [-m/--r-min &lt;r_min&gt;] [-f/--function &lt;scoring_function&gt;] [-e/--ess &lt;ess&gt;] [-p/--max-parents &lt;max_parents&gt;] [--enable-de-campos-pruning] [-t/--threads &lt;threads&gt;] [-r/--time &lt;running_time&gt;] [-s/--has-header] [-o/--do-not-prune]</code></pre>
<h3 id="command-line-options">Command line options</h3>
<ul>
<li><p><code>input</code>. The input csv file</p></li>
<li><p><code>output</code>. The output pss file</p></li>
<li><p>[<code>--constraints</code>]. A file containing simple constraints on the parent sets. Please see the <a href="constraints.html">constraints description</a> for more details on this file.</p></li>
<li><p>[<code>--delimiter</code>]. The character which separates columns in the <code>input</code> file. <strong>N.B.</strong> The actual data type is <code>char</code>, so only a single character is allowed. Default: <code>,</code></p></li>
<li><p>[<code>--has-header</code>]. Add this flag if the first line of <code>input</code> gives the name of the variables. It should use the same <code>delimiter</code> as the rest of the file. Default: variables are given names like <code>Variable_0</code>.</p></li>
<li><p>[<code>--r-min</code>]. Internally, the program uses a sparse AD-tree to collect the necessary counts. This parameter controls the minimum number of records in the leaves of the AD-tree. Default: 5. For more details, please see:</p>
<p>Moore, A. &amp; Lee, M. S. Cached sufficient statistics for efficient machine learning with large datasets. <em>Journal of Artificial Intelligence Research</em>, 1998, 8, 67-91 (Section 5).</p></li>
<li><p>[<code>--function</code>]. The scoring function to use. Default: <code>BIC</code>. Choices: <code>BIC</code>, <code>fNML</code>, <code>BDeu</code> (case-insensitive). <strong>N.B.</strong> For all scoring functions, the natural logarithm is used for all relevant calculations, and <code>log(0)</code> is taken to be <code>0</code>.</p></li>
<li><p>[<code>--ess</code>]. The equivalent sample size for BDeu. This parameter is ignored for the other scoring functions. Default: 1.0</p></li>
<li><p>[<code>--max-parents</code>]. The maximum number of parents to consider for local scores. Additionally, for BIC, the literature shows a hard limit on the number of parents as a function of the number of records. If the <code>--do-not-prune</code> flag is given, <code>max_parents</code> will not be updates; otherwise, <code>max_parents</code> will be set to this limit for <code>BIC</code>. A value less than 1 indicates no limit on the sizes of the candidate parent sets. Default: 0. For more details, please see:</p>
<p>Suzuki, J. Learning Bayesian Belief Networks Based on the MDL Principle: An Efficient Algorithm Using the Branch and Bound Technique. <em>IEICE Transactions on Information and Systems</em>, 1999, E82-D, 356-367.</p></li>
<li><p>[<code>--enable-de-campos-pruning</code>]. Add this flag to <em>enable</em> de Campos and Ji-style score pruning during the search. This feature is experimental (unpublished) for fNML, and it appears to have a bug for large parent limits and BDeu. Please follow <a href="https://github.com/bmmalone/urlearning-cpp/issues/20">Issue #20</a> for updates about the correctness. Default: all local scores are calculated, up to the <code>max_parents</code> limit. For more details, please see:</p>
<p>de Campos, C. P. &amp; Ji, Q. Efficient Learning of Bayesian Networks using Constraints. <em>Journal of Machine Learning Research</em>, 2011, 12, 663-689.</p></li>
<li><p>[<code>--do-not-prune</code>]. Add this flag to <em>disable</em> standard score pruning after score calculations. Additionally, this flag <em>disables</em> the automatic <code>max_parent</code> calculation for <code>BIC</code> (as described for <code>--max-parents</code>). Default: scores are pruned according to the Teyssier and Koller reference given above, and the parent limit for <code>BIC</code> is set according to the rule given by Suzuki.</p></li>
<li><p>[<code>--threads</code>]. The number of concurrent threads to use for score calculations. The parallelism is very simple; each thread calculates the candidate parent sets for one of the variables and writes them to a temporary pss file. After all candidate parent sets have been calculated, the pss files are concatenated into the final pss file containing all scores. Default: 1</p></li>
<li><p>[<code>--time</code>]. The maximum amount of time (in seconds) to use for calculating local scores for each variable. After the specified time has elapsed, local score calculations will end after the calculation of the “current” score, and the candidate parent sets will be found using Teyssier and Koller pruning (unless the <code>--do-not-prune</code> flag was given). A value less than 1 indicates no time limit and all scores will be calculated according to the specified parameters. Default: 0.</p></li>
</ul>
</body>
</html>
